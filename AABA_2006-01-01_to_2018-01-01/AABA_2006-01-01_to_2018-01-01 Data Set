import warnings; warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import seaborn as sns

# FILE_PATH = "AABA_2006-01-01_to_2018-01-01.csv"
# df = pd.read_csv(FILE_PATH)

df = pd.read_csv("AABA_2006-01-01_to_2018-01-01.csv")

print("Columns:", list(df.columns))
print("Head:\n", df.head(3), "\n")

df = df.dropna().copy()
preferred_targets = ['Adj Close', 'Adj_Close', 'adj close', 'Close', 'close']
target_col = None
for c in df.columns:
    if c.lower() in [t.lower() for t in preferred_targets]:
        target_col = c
        break
if target_col is None:
    raise ValueError("No target column found (expected one of: Adj Close / Close).")

if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['DayOfWeek'] = df['Date'].dt.dayofweek
    df = df.drop(columns=['Date'])

y = pd.to_numeric(df[target_col], errors='coerce')

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
X_cols = [c for c in numeric_cols if c != target_col]
if not X_cols:
    raise ValueError("No numeric feature columns found after cleaning.")

X = df[X_cols].astype(float)

print(f"Using target: {target_col}")
print("Feature columns:", X_cols)
print("X shape:", X.shape, " y shape:", y.shape)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)   
X_test_scaled  = scaler.transform(X_test)

ml_model = RandomForestRegressor(
    n_estimators=200, max_depth=None, random_state=42, n_jobs=-1
)
ml_model.fit(X_train_scaled, y_train)
y_pred_ml = ml_model.predict(X_test_scaled)

print("\nML Model (RandomForest):")
print(" MSE :", mean_squared_error(y_test, y_pred_ml))
print(" R^2 :", r2_score(y_test, y_pred_ml))

tf.random.set_seed(42)

dl_model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)
])
dl_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = dl_model.fit(
    X_train_scaled, y_train,
    validation_data=(X_test_scaled, y_test),
    epochs=20, batch_size=32, verbose=1
)

loss, mae = dl_model.evaluate(X_test_scaled, y_test, verbose=0)
y_pred_dl = dl_model.predict(X_test_scaled, verbose=0).ravel()

print("\nDL Model (Keras):")
print(" Loss (MSE):", loss)
print(" MAE       :", mae)
print(" R^2       :", r2_score(y_test, y_pred_dl))

tips= sns.load_dataset("tips")
plt.figure(figsize=(8,6))
sns.boxplot(x="day", y="total_bill", data=tips)
plt.title("Boxplot of Total Bill by Day")
plt.show()
sns.set_style("white")
sns.stripplot(x="day", y="total_bill", data=tips)
sns.despine()
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10,6))
plt.barh(X_cols, ml_model.feature_importances_)
plt.title("Feature Importance (DL Model)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

sns.set(style="darkgrid")
plt.figure(figsize=(10,6))
sns.heatmap(X.corr(), annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title("Feature Correlation Heatmap")
plt.tight_layout()
plt.show()
sns.set(style="ticks")
plt.figure(figsize=(10,6))
sns.boxplot(data=df[X_cols])
plt.figure(figsize=(8,5))

sns.set(style="ticks")
plt.figure(figsize=(10,6))
sns.boxplot(data=df[X_cols])
plt.figure(figsize=(8,5))

sns.set_style("white")
sns.stripplot(x="day", y="total_bill", data=tips)
sns.despine()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch'); plt.ylabel('MSE'); plt.title('DL Training Performance')
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred_ml, alpha=0.6, label="RandomForest")
plt.scatter(y_test, y_pred_dl, alpha=0.6, color="red", label="Deep Learning")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Model Prediction Comparison")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
